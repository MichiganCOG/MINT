#!/bin/bash
#PBS -N ALG1B_MNIST_MLP_20g_RETRAIN
#PBS -t 1-71%10
#PBS -j oe
#PBS -l walltime=00:10:00
#PBS -l nodes=1:ppn=16:gpus=1

IFS=$'\n' allocatedgpus=($(sed -e 's/.*-gpu\([0-9]\+\)/\1/' $PBS_GPUFILE))
echo I got allocated the following gpus
for g in "${allocatedgpus[@]}"; do
    echo "gpu: $g"
done


export CUDA_VISIBLE_DEVICES="${allocatedgpus[0]}"
echo "Start Job"

cd ~/MINT/
source setup.sh 

cd MINT/mlp

python retrain_stage3.py \
--Epoch 30 \
--Batch_size 256 \
--Lr 0.1 \
--Dataset MNIST \
--Dims 10 \
--Expt_rerun 1 \
--Milestones 10 20 \
--Opt sgd \
--Weight_decay 0.0001 \
--Model mlp \
--Gamma 0.1 \
--Nesterov \
--Device_ids 0 \
--Retrain BASELINE_MNIST_MLP/0/logits_best.pkl \
--Retrain_mask BASELINE_MNIST_MLP/0/I_parent_20g_1b.npy \
--Labels_file BASELINE_MNIST_MLP/0/Labels_20g_1b.npy \
--Labels_children_file BASELINE_MNIST_MLP/0/Labels_children_20g_1b.npy \
--parent_key   fc1.weight fc2.weight \
--children_key fc2.weight fc3.weight \
--parent_clusters   20 20 \
--children_clusters 20 10 \
--upper_prune_limit 1.1 \
--upper_prune_per 0.95 \
--lower_prune_per 0.1 \
--prune_per_step 0.012 \
--Save_dir BASELINE_MNIST_MLP_RETRAIN_1 \
--key_id $PBS_ARRAYID

echo "End Job"
